{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "try:\n",
    "    import ujson as json\n",
    "except ModuleNotFoundError:\n",
    "    ! pip install ujson -qU\n",
    "    ! pip install umap-learn -qU\n",
    "    import ujson as json\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    on_colab = True\n",
    "    # assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
    "    # !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl -qU\n",
    "    !pip install pytorch-lightning -qU\n",
    "else:\n",
    "    on_colab = False\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Helper function to download files\n",
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as ff:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                ff.write(chunk)\n",
    "    return local_filename"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper function to pick random parameter from iterable or range\n",
    "def random_element(parameter_iterable):\n",
    "    # If it's a tuple treat it as an upper and lower bound\n",
    "    if isinstance(parameter_iterable, tuple):\n",
    "        out = random.uniform(parameter_iterable[0], parameter_iterable[1])\n",
    "        return round(out, 6)\n",
    "\n",
    "    # If it's a list, return a random element from the list\n",
    "    elif isinstance(parameter_iterable, list):\n",
    "        no_choices = len(parameter_iterable)\n",
    "        return parameter_iterable[random.randrange(0, no_choices)]\n",
    "\n",
    "    else:\n",
    "        print('Input not a tuple or list.')\n",
    "        raise TypeError"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def randomize_hparams():\n",
    "\n",
    "    parameters_ = {\n",
    "        'l2_norm': random_element((0.05, 0.75)),\n",
    "        'batch_size': 256,\n",
    "                  'learning_rate': random_element((0.1, 1e-3)),\n",
    "                  'lr_scheduler_factor': random_element((0.1, 1)),\n",
    "                  'lr_scheduler_patience': random_element([2, 4, 8, 16]),\n",
    "                  'lr_scheduler_min_lr': random_element((1e-8, 1e-2)),\n",
    "                  'hidden_layer_size': random_element([16, 24, 32, 64, 96, 128]),\n",
    "                    'gradient_clip_val': random_element((0.4, 2)),\n",
    "        'stochastic_weight_avg': random_element([True, False]),\n",
    "        'gradient_clip_algorithm': random_element(['norm', 'value']),\n",
    "                          }\n",
    "\n",
    "    return parameters_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    0         1         2    \\\n3865991_3865991_691412_2935874-DSMUXGTJ-7.jpg  0.402192  0.215186  1.006052   \n7980766_7980766_669333_7048178-XOYQRJZQ-7.jpg  1.073950  0.707743  0.106056   \n3749936_3749936_314728_2819820-JDANXKLD-7.jpg  2.806773  0.006849  0.898165   \n5610715_5610715_91068_4680525-LMQNOWJA-7.jpg   0.039423  0.658119  1.192224   \n6771765_6771765_786228_5841405-PSPFNCAV-7.jpg  0.292377  0.011645  0.000842   \n\n                                                    3         4         5    \\\n3865991_3865991_691412_2935874-DSMUXGTJ-7.jpg  2.535887  0.223182  0.966906   \n7980766_7980766_669333_7048178-XOYQRJZQ-7.jpg  0.551383  0.680530  1.220285   \n3749936_3749936_314728_2819820-JDANXKLD-7.jpg  0.802126  0.967394  0.287235   \n5610715_5610715_91068_4680525-LMQNOWJA-7.jpg   2.684522  2.460881  0.046748   \n6771765_6771765_786228_5841405-PSPFNCAV-7.jpg  1.337585  0.382337  0.305897   \n\n                                                    6         7         8    \\\n3865991_3865991_691412_2935874-DSMUXGTJ-7.jpg  0.067344  3.101986  1.115319   \n7980766_7980766_669333_7048178-XOYQRJZQ-7.jpg  1.024527  0.305020  1.039700   \n3749936_3749936_314728_2819820-JDANXKLD-7.jpg  0.244238  1.446031  6.778771   \n5610715_5610715_91068_4680525-LMQNOWJA-7.jpg   0.357242  3.366874  0.919030   \n6771765_6771765_786228_5841405-PSPFNCAV-7.jpg  0.060697  0.592383  1.287450   \n\n                                                    9    ...       502  \\\n3865991_3865991_691412_2935874-DSMUXGTJ-7.jpg  0.726254  ...  0.732725   \n7980766_7980766_669333_7048178-XOYQRJZQ-7.jpg  0.217051  ...  0.649347   \n3749936_3749936_314728_2819820-JDANXKLD-7.jpg  0.235296  ...  1.267828   \n5610715_5610715_91068_4680525-LMQNOWJA-7.jpg   0.776935  ...  0.823428   \n6771765_6771765_786228_5841405-PSPFNCAV-7.jpg  0.122081  ...  0.067053   \n\n                                                    503       504       505  \\\n3865991_3865991_691412_2935874-DSMUXGTJ-7.jpg  0.914586  0.618770  0.791526   \n7980766_7980766_669333_7048178-XOYQRJZQ-7.jpg  1.637149  2.630768  2.322523   \n3749936_3749936_314728_2819820-JDANXKLD-7.jpg  0.326778  0.115728  0.466623   \n5610715_5610715_91068_4680525-LMQNOWJA-7.jpg   0.713102  0.531813  1.427407   \n6771765_6771765_786228_5841405-PSPFNCAV-7.jpg  0.803128  0.234250  2.015079   \n\n                                                    506       507       508  \\\n3865991_3865991_691412_2935874-DSMUXGTJ-7.jpg  2.018329  0.108899  0.651192   \n7980766_7980766_669333_7048178-XOYQRJZQ-7.jpg  0.047876  1.300324  3.735312   \n3749936_3749936_314728_2819820-JDANXKLD-7.jpg  0.193548  1.720899  1.446586   \n5610715_5610715_91068_4680525-LMQNOWJA-7.jpg   0.424931  2.481088  0.868538   \n6771765_6771765_786228_5841405-PSPFNCAV-7.jpg  1.405711  0.291771  0.038078   \n\n                                                    509       510       511  \n3865991_3865991_691412_2935874-DSMUXGTJ-7.jpg  0.192771  2.346089  1.501905  \n7980766_7980766_669333_7048178-XOYQRJZQ-7.jpg  1.352288  0.054118  3.584239  \n3749936_3749936_314728_2819820-JDANXKLD-7.jpg  2.535370  0.864782  0.062465  \n5610715_5610715_91068_4680525-LMQNOWJA-7.jpg   2.333207  0.845097  1.062181  \n6771765_6771765_786228_5841405-PSPFNCAV-7.jpg  0.586244  0.069435  0.066380  \n\n[5 rows x 512 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>502</th>\n      <th>503</th>\n      <th>504</th>\n      <th>505</th>\n      <th>506</th>\n      <th>507</th>\n      <th>508</th>\n      <th>509</th>\n      <th>510</th>\n      <th>511</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3865991_3865991_691412_2935874-DSMUXGTJ-7.jpg</th>\n      <td>0.402192</td>\n      <td>0.215186</td>\n      <td>1.006052</td>\n      <td>2.535887</td>\n      <td>0.223182</td>\n      <td>0.966906</td>\n      <td>0.067344</td>\n      <td>3.101986</td>\n      <td>1.115319</td>\n      <td>0.726254</td>\n      <td>...</td>\n      <td>0.732725</td>\n      <td>0.914586</td>\n      <td>0.618770</td>\n      <td>0.791526</td>\n      <td>2.018329</td>\n      <td>0.108899</td>\n      <td>0.651192</td>\n      <td>0.192771</td>\n      <td>2.346089</td>\n      <td>1.501905</td>\n    </tr>\n    <tr>\n      <th>7980766_7980766_669333_7048178-XOYQRJZQ-7.jpg</th>\n      <td>1.073950</td>\n      <td>0.707743</td>\n      <td>0.106056</td>\n      <td>0.551383</td>\n      <td>0.680530</td>\n      <td>1.220285</td>\n      <td>1.024527</td>\n      <td>0.305020</td>\n      <td>1.039700</td>\n      <td>0.217051</td>\n      <td>...</td>\n      <td>0.649347</td>\n      <td>1.637149</td>\n      <td>2.630768</td>\n      <td>2.322523</td>\n      <td>0.047876</td>\n      <td>1.300324</td>\n      <td>3.735312</td>\n      <td>1.352288</td>\n      <td>0.054118</td>\n      <td>3.584239</td>\n    </tr>\n    <tr>\n      <th>3749936_3749936_314728_2819820-JDANXKLD-7.jpg</th>\n      <td>2.806773</td>\n      <td>0.006849</td>\n      <td>0.898165</td>\n      <td>0.802126</td>\n      <td>0.967394</td>\n      <td>0.287235</td>\n      <td>0.244238</td>\n      <td>1.446031</td>\n      <td>6.778771</td>\n      <td>0.235296</td>\n      <td>...</td>\n      <td>1.267828</td>\n      <td>0.326778</td>\n      <td>0.115728</td>\n      <td>0.466623</td>\n      <td>0.193548</td>\n      <td>1.720899</td>\n      <td>1.446586</td>\n      <td>2.535370</td>\n      <td>0.864782</td>\n      <td>0.062465</td>\n    </tr>\n    <tr>\n      <th>5610715_5610715_91068_4680525-LMQNOWJA-7.jpg</th>\n      <td>0.039423</td>\n      <td>0.658119</td>\n      <td>1.192224</td>\n      <td>2.684522</td>\n      <td>2.460881</td>\n      <td>0.046748</td>\n      <td>0.357242</td>\n      <td>3.366874</td>\n      <td>0.919030</td>\n      <td>0.776935</td>\n      <td>...</td>\n      <td>0.823428</td>\n      <td>0.713102</td>\n      <td>0.531813</td>\n      <td>1.427407</td>\n      <td>0.424931</td>\n      <td>2.481088</td>\n      <td>0.868538</td>\n      <td>2.333207</td>\n      <td>0.845097</td>\n      <td>1.062181</td>\n    </tr>\n    <tr>\n      <th>6771765_6771765_786228_5841405-PSPFNCAV-7.jpg</th>\n      <td>0.292377</td>\n      <td>0.011645</td>\n      <td>0.000842</td>\n      <td>1.337585</td>\n      <td>0.382337</td>\n      <td>0.305897</td>\n      <td>0.060697</td>\n      <td>0.592383</td>\n      <td>1.287450</td>\n      <td>0.122081</td>\n      <td>...</td>\n      <td>0.067053</td>\n      <td>0.803128</td>\n      <td>0.234250</td>\n      <td>2.015079</td>\n      <td>1.405711</td>\n      <td>0.291771</td>\n      <td>0.038078</td>\n      <td>0.586244</td>\n      <td>0.069435</td>\n      <td>0.066380</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 512 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load x data\n",
    "if on_colab:\n",
    "    download_file('https://objectstorage.eu-frankfurt-1.oraclecloud.com/n/frwwzrj6ghal/b/thesis/o/micro_dataset1_resnet18_output_identity.json')\n",
    "    data_dir = r'micro_dataset1_resnet18_output_identity.json'\n",
    "else:\n",
    "    data_dir = r'F:\\temp\\thesisdata\\micro_dataset_1\\micro_dataset1_resnet18_output_identity.json'\n",
    "\n",
    "with open(data_dir, 'r') as f:\n",
    "    data_dict_list = json.load(f)\n",
    "\n",
    "data_dict = {}\n",
    "for element in data_dict_list:\n",
    "    data_dict.update(element)\n",
    "\n",
    "# Show first two elements of the dict\n",
    "# dict(itertools.islice(data_dict.items(), 2))\n",
    "df_x = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "df_x.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             PRICE_BIN_IDX  \\\nFILENAME                                                     \n481029_481029_349215_257967-7.jpg                        2   \n511001_511001_388280_276511-7.jpg                        3   \n517326_517326_376595_282597-CCCWLPRX-7.jpg               4   \n524310_524310_342634_286117-LEMCITZY-7.jpg               4   \n5045187_5045187_7198_4115009-DDZJITSS-7.jpg              2   \n\n                                             LIKES_VIEWS_RATIO_BIN_IDX  \nFILENAME                                                                \n481029_481029_349215_257967-7.jpg                                    1  \n511001_511001_388280_276511-7.jpg                                    0  \n517326_517326_376595_282597-CCCWLPRX-7.jpg                           0  \n524310_524310_342634_286117-LEMCITZY-7.jpg                           0  \n5045187_5045187_7198_4115009-DDZJITSS-7.jpg                          1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRICE_BIN_IDX</th>\n      <th>LIKES_VIEWS_RATIO_BIN_IDX</th>\n    </tr>\n    <tr>\n      <th>FILENAME</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>481029_481029_349215_257967-7.jpg</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>511001_511001_388280_276511-7.jpg</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>517326_517326_376595_282597-CCCWLPRX-7.jpg</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>524310_524310_342634_286117-LEMCITZY-7.jpg</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5045187_5045187_7198_4115009-DDZJITSS-7.jpg</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load y data\n",
    "if on_colab:\n",
    "    download_file('https://objectstorage.eu-frankfurt-1.oraclecloud.com/n/frwwzrj6ghal/b/thesis/o/SAATCHI_MICRO_DATASET_PRICE_VIEWSLIKES.tsv')\n",
    "    data_dir = 'SAATCHI_MICRO_DATASET_PRICE_VIEWSLIKES.tsv'\n",
    "else:\n",
    "    data_dir = r'F:\\temp\\thesisdata\\SAATCHI_MICRO_DATASET_PRICE_VIEWSLIKES.tsv'\n",
    "\n",
    "df_y = pd.read_csv(data_dir, sep='\\t')\n",
    "df_y.set_index('FILENAME', inplace=True)\n",
    "\n",
    "# Bin the data\n",
    "# df_y['PRICE_BIN'] = pd.qcut(df_y['PRICE'], q=5)\n",
    "df_y['PRICE_BIN_IDX'] = pd.qcut(df_y['PRICE'], q=5, labels=[0, 1, 2, 3, 4])\n",
    "# df_y['LIKES_VIEWS_RATIO_BIN'] = pd.qcut(df_y['LIKES_VIEWS_RATIO'], q=5)\n",
    "df_y['LIKES_VIEWS_RATIO_BIN_IDX'] = pd.qcut(df_y['LIKES_VIEWS_RATIO'], q=5, labels=[0, 1, 2, 3, 4])\n",
    "df_y = df_y.astype({'PRICE_BIN_IDX': int, 'LIKES_VIEWS_RATIO_BIN_IDX': int})\n",
    "df_y.drop(['PRICE', 'LIKES_VIEWS_RATIO'], axis=1, inplace=True)\n",
    "\n",
    "df_y.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             PRICE_BIN_IDX  \\\n1008695_1008695_16575_492565-WPTALJUX-7.jpg              4   \n1020928_1020928_20375_496298-MVOEZUTF-7.jpg              1   \n1051436_1051436_17127_506738-INLFTOGF-7.jpg              1   \n1055377_1055377_18467_508857-HYTIVNMU-7.jpg              3   \n1057504_1057504_19082_509430-EKIORJVM-7.jpg              4   \n\n                                             LIKES_VIEWS_RATIO_BIN_IDX  \\\n1008695_1008695_16575_492565-WPTALJUX-7.jpg                          0   \n1020928_1020928_20375_496298-MVOEZUTF-7.jpg                          0   \n1051436_1051436_17127_506738-INLFTOGF-7.jpg                          1   \n1055377_1055377_18467_508857-HYTIVNMU-7.jpg                          0   \n1057504_1057504_19082_509430-EKIORJVM-7.jpg                          1   \n\n                                                    0         1         2  \\\n1008695_1008695_16575_492565-WPTALJUX-7.jpg  0.506733  1.394197  0.142876   \n1020928_1020928_20375_496298-MVOEZUTF-7.jpg  0.833585  1.465594  0.606634   \n1051436_1051436_17127_506738-INLFTOGF-7.jpg  1.898964  0.537831  0.355688   \n1055377_1055377_18467_508857-HYTIVNMU-7.jpg  0.959911  1.014624  0.928045   \n1057504_1057504_19082_509430-EKIORJVM-7.jpg  1.535582  0.951705  0.470121   \n\n                                                    3         4         5  \\\n1008695_1008695_16575_492565-WPTALJUX-7.jpg  1.595724  0.447865  2.721004   \n1020928_1020928_20375_496298-MVOEZUTF-7.jpg  0.643496  0.979372  1.374905   \n1051436_1051436_17127_506738-INLFTOGF-7.jpg  1.914660  0.678449  0.122319   \n1055377_1055377_18467_508857-HYTIVNMU-7.jpg  0.345727  0.310256  0.644479   \n1057504_1057504_19082_509430-EKIORJVM-7.jpg  2.631895  0.672225  0.481367   \n\n                                                    6         7  ...  \\\n1008695_1008695_16575_492565-WPTALJUX-7.jpg  0.549245  0.088606  ...   \n1020928_1020928_20375_496298-MVOEZUTF-7.jpg  1.059826  0.382815  ...   \n1051436_1051436_17127_506738-INLFTOGF-7.jpg  0.920843  0.896121  ...   \n1055377_1055377_18467_508857-HYTIVNMU-7.jpg  0.349452  1.512597  ...   \n1057504_1057504_19082_509430-EKIORJVM-7.jpg  0.571308  0.184078  ...   \n\n                                                  502       503       504  \\\n1008695_1008695_16575_492565-WPTALJUX-7.jpg  0.514084  1.684672  2.690634   \n1020928_1020928_20375_496298-MVOEZUTF-7.jpg  0.505261  1.688515  0.417936   \n1051436_1051436_17127_506738-INLFTOGF-7.jpg  0.213230  0.716053  0.299384   \n1055377_1055377_18467_508857-HYTIVNMU-7.jpg  0.680928  2.470096  2.451149   \n1057504_1057504_19082_509430-EKIORJVM-7.jpg  0.659331  0.722163  1.269953   \n\n                                                  505       506       507  \\\n1008695_1008695_16575_492565-WPTALJUX-7.jpg  1.076642  1.014139  0.403866   \n1020928_1020928_20375_496298-MVOEZUTF-7.jpg  0.200680  1.674028  1.199314   \n1051436_1051436_17127_506738-INLFTOGF-7.jpg  2.024731  0.045484  1.757237   \n1055377_1055377_18467_508857-HYTIVNMU-7.jpg  3.417884  1.716235  0.149804   \n1057504_1057504_19082_509430-EKIORJVM-7.jpg  0.223978  1.508935  0.835212   \n\n                                                  508       509       510  \\\n1008695_1008695_16575_492565-WPTALJUX-7.jpg  1.054885  1.213333  0.088460   \n1020928_1020928_20375_496298-MVOEZUTF-7.jpg  0.406038  1.510623  0.472602   \n1051436_1051436_17127_506738-INLFTOGF-7.jpg  0.775970  2.071618  0.271196   \n1055377_1055377_18467_508857-HYTIVNMU-7.jpg  0.000000  1.423536  0.022786   \n1057504_1057504_19082_509430-EKIORJVM-7.jpg  2.030264  1.891201  0.333001   \n\n                                                  511  \n1008695_1008695_16575_492565-WPTALJUX-7.jpg  0.786160  \n1020928_1020928_20375_496298-MVOEZUTF-7.jpg  1.073225  \n1051436_1051436_17127_506738-INLFTOGF-7.jpg  1.722807  \n1055377_1055377_18467_508857-HYTIVNMU-7.jpg  0.289719  \n1057504_1057504_19082_509430-EKIORJVM-7.jpg  2.909141  \n\n[5 rows x 514 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRICE_BIN_IDX</th>\n      <th>LIKES_VIEWS_RATIO_BIN_IDX</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>502</th>\n      <th>503</th>\n      <th>504</th>\n      <th>505</th>\n      <th>506</th>\n      <th>507</th>\n      <th>508</th>\n      <th>509</th>\n      <th>510</th>\n      <th>511</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1008695_1008695_16575_492565-WPTALJUX-7.jpg</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0.506733</td>\n      <td>1.394197</td>\n      <td>0.142876</td>\n      <td>1.595724</td>\n      <td>0.447865</td>\n      <td>2.721004</td>\n      <td>0.549245</td>\n      <td>0.088606</td>\n      <td>...</td>\n      <td>0.514084</td>\n      <td>1.684672</td>\n      <td>2.690634</td>\n      <td>1.076642</td>\n      <td>1.014139</td>\n      <td>0.403866</td>\n      <td>1.054885</td>\n      <td>1.213333</td>\n      <td>0.088460</td>\n      <td>0.786160</td>\n    </tr>\n    <tr>\n      <th>1020928_1020928_20375_496298-MVOEZUTF-7.jpg</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0.833585</td>\n      <td>1.465594</td>\n      <td>0.606634</td>\n      <td>0.643496</td>\n      <td>0.979372</td>\n      <td>1.374905</td>\n      <td>1.059826</td>\n      <td>0.382815</td>\n      <td>...</td>\n      <td>0.505261</td>\n      <td>1.688515</td>\n      <td>0.417936</td>\n      <td>0.200680</td>\n      <td>1.674028</td>\n      <td>1.199314</td>\n      <td>0.406038</td>\n      <td>1.510623</td>\n      <td>0.472602</td>\n      <td>1.073225</td>\n    </tr>\n    <tr>\n      <th>1051436_1051436_17127_506738-INLFTOGF-7.jpg</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1.898964</td>\n      <td>0.537831</td>\n      <td>0.355688</td>\n      <td>1.914660</td>\n      <td>0.678449</td>\n      <td>0.122319</td>\n      <td>0.920843</td>\n      <td>0.896121</td>\n      <td>...</td>\n      <td>0.213230</td>\n      <td>0.716053</td>\n      <td>0.299384</td>\n      <td>2.024731</td>\n      <td>0.045484</td>\n      <td>1.757237</td>\n      <td>0.775970</td>\n      <td>2.071618</td>\n      <td>0.271196</td>\n      <td>1.722807</td>\n    </tr>\n    <tr>\n      <th>1055377_1055377_18467_508857-HYTIVNMU-7.jpg</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0.959911</td>\n      <td>1.014624</td>\n      <td>0.928045</td>\n      <td>0.345727</td>\n      <td>0.310256</td>\n      <td>0.644479</td>\n      <td>0.349452</td>\n      <td>1.512597</td>\n      <td>...</td>\n      <td>0.680928</td>\n      <td>2.470096</td>\n      <td>2.451149</td>\n      <td>3.417884</td>\n      <td>1.716235</td>\n      <td>0.149804</td>\n      <td>0.000000</td>\n      <td>1.423536</td>\n      <td>0.022786</td>\n      <td>0.289719</td>\n    </tr>\n    <tr>\n      <th>1057504_1057504_19082_509430-EKIORJVM-7.jpg</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1.535582</td>\n      <td>0.951705</td>\n      <td>0.470121</td>\n      <td>2.631895</td>\n      <td>0.672225</td>\n      <td>0.481367</td>\n      <td>0.571308</td>\n      <td>0.184078</td>\n      <td>...</td>\n      <td>0.659331</td>\n      <td>0.722163</td>\n      <td>1.269953</td>\n      <td>0.223978</td>\n      <td>1.508935</td>\n      <td>0.835212</td>\n      <td>2.030264</td>\n      <td>1.891201</td>\n      <td>0.333001</td>\n      <td>2.909141</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 514 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join x and y into a single dataframe\n",
    "df = df_y.join(df_x)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class SaatchiDataset(Dataset):\n",
    "    training_set = df[:13000]\n",
    "    validation_set = df[13000:14000]\n",
    "    test_set = df[14000:]\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return self.targets_\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        return self.data_\n",
    "\n",
    "    def __init__(self, stage: str = None, target_selection=None):\n",
    "        self.stage = stage\n",
    "        self.target_selection = target_selection\n",
    "\n",
    "        if self.stage == 'train':\n",
    "            self.dataset = self.training_set\n",
    "        elif self.stage == 'validation':\n",
    "            self.dataset = self.validation_set\n",
    "        elif self.stage == 'test':\n",
    "            self.dataset = self.test_set\n",
    "        else:\n",
    "            print(f'Invalid stage specified: \"{stage}\" , valid options are: [train, validation, test].')\n",
    "            self.dataset = None\n",
    "\n",
    "        self.data_ = self.dataset.drop(['PRICE_BIN_IDX', 'LIKES_VIEWS_RATIO_BIN_IDX'], axis=1).values\n",
    "\n",
    "        if self.target_selection == 'price':\n",
    "            self.targets_ = self.dataset['PRICE_BIN_IDX'].values\n",
    "        elif self.target_selection == 'likes_view_ratio':\n",
    "            self.targets_ = self.dataset['LIKES_VIEWS_RATIO_BIN_IDX'].values\n",
    "        else:\n",
    "            print(\n",
    "                f'Invalid target selection specified: \"{target_selection}\"'\n",
    "                f', valid options are: [price, likes_view_ratio].')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.as_tensor(self.data_[index]).float(), torch.as_tensor(self.targets_[index]).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class SaatchiDataModule(pl.LightningDataModule):\n",
    "  def __init__(self,\n",
    "               batch_size: int = 64,\n",
    "               num_workers: int = 4,\n",
    "               target_selection: str = 'price'):\n",
    "    super().__init__()\n",
    "    self.batch_size = hparams['batch_size']\n",
    "    self.data = None\n",
    "    self.num_workers = num_workers\n",
    "    self.target_selection = target_selection\n",
    "\n",
    "  def prepare_data(self):\n",
    "      pass\n",
    "\n",
    "  def setup(self, stage: str = None):\n",
    "    if stage == 'fit':\n",
    "      self.data = SaatchiDataset(stage='train', target_selection=self.target_selection)\n",
    "    else:\n",
    "      self.data = SaatchiDataset(stage=stage, target_selection=self.target_selection)\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(self.data,\n",
    "                      batch_size=self.batch_size,\n",
    "                      drop_last=True,\n",
    "                      num_workers=self.num_workers)\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(self.data,\n",
    "                      batch_size=self.batch_size,\n",
    "                      drop_last=True,\n",
    "                      num_workers=self.num_workers)\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    return DataLoader(self.data,\n",
    "                      batch_size=self.batch_size,\n",
    "                      drop_last=True,\n",
    "                      num_workers=self.num_workers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class SaatchiMLP(pl.LightningModule):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.hparams.hidden_layer_size = hparams['hidden_layer_size']\n",
    "    self.hparams.l2_norm = hparams['l2_norm']\n",
    "    self.hparams.lr = hparams['learning_rate']\n",
    "    self.hparams.lr_scheduler_factor = hparams['lr_scheduler_factor']\n",
    "    self.hparams.lr_scheduler_patience = hparams['lr_scheduler_patience']\n",
    "    self.hparams.lr_scheduler_min_lr = hparams['lr_scheduler_min_lr']\n",
    "\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(512, self.hparams.hidden_layer_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(self.hparams.hidden_layer_size, 5)\n",
    "    )\n",
    "    self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    x = x.view(x.size(0), -1)\n",
    "    y_hat = self.layers(x)\n",
    "    loss = self.ce(y_hat, y)\n",
    "    self.log('train_loss', loss)\n",
    "\n",
    "    # Logic for calculating and printing accuracy\n",
    "    step_counter.increment()\n",
    "    if step_counter.step_count % 100 == 0:\n",
    "\n",
    "        pred = np.array([x.argmax() for x in y_hat.cpu().detach().numpy()])\n",
    "        y_ = y.cpu().detach().numpy()\n",
    "        correct_preds = np.sum(y_ == pred)\n",
    "        acc = round(correct_preds / y_.shape[0], 4)\n",
    "        # print(f'y_hat = {y_hat}; y = {y}')\n",
    "        # print(f'Accuracy at step {step_counter.step_count}: {acc}')\n",
    "        accuracy_tracker.register_accuracy(accuracy_value=acc)\n",
    "        # print(f'Loss at step {loss}')\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    x = x.view(x.size(0), -1)\n",
    "    y_hat = self.layers(x)\n",
    "    # print(f'y = {y}; y_hat = {y_hat}')\n",
    "    loss = self.ce(y_hat, y)\n",
    "    self.log('validation_loss', loss)\n",
    "    # print(f'Loss at validation {loss}')\n",
    "    return loss\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                 lr=self.hparams.lr,\n",
    "                                 weight_decay=self.hparams.l2_norm)\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                            factor=self.hparams.lr_scheduler_factor,\n",
    "                                                            patience=self.hparams.lr_scheduler_patience,\n",
    "                                                            min_lr=self.hparams.lr_scheduler_min_lr,\n",
    "                                                            verbose=False)\n",
    "\n",
    "    scheduler = {\n",
    "            'scheduler': lr_scheduler,\n",
    "            'monitor': 'validation_loss',\n",
    "            'reduce_on_plateau': True\n",
    "        }\n",
    "\n",
    "    return [optimizer], [scheduler]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "C:\\Users\\R\\anaconda3\\envs\\Thesis_cur-AI-tor\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping val loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name   | Type             | Params\n",
      "--------------------------------------------\n",
      "0 | layers | Sequential       | 3.0 K \n",
      "1 | ce     | CrossEntropyLoss | 0     \n",
      "--------------------------------------------\n",
      "3.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f921e643f3984ef5b227bac9c421826a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class AccuracyTracker(object):\n",
    "  def __init__(self, run):\n",
    "    self.accuracy = 0.0\n",
    "    self.accuracy_list = list()\n",
    "    self.run_number = run\n",
    "\n",
    "  def register_accuracy(self, accuracy_value):\n",
    "    self.accuracy_list.append({self.run_number: accuracy_value})\n",
    "    if accuracy_value > self.accuracy:\n",
    "      self.accuracy = accuracy_value\n",
    "\n",
    "  @property\n",
    "  def get_accuracy_value(self):\n",
    "    return self.accuracy\n",
    "\n",
    "class StepCounter(object):\n",
    "    def __init__(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "    def increment(self):\n",
    "        self.step_count = self.step_count + 1\n",
    "\n",
    "    @property\n",
    "    def get_step_count(self):\n",
    "        return self.step_count\n",
    "\n",
    "hparams = randomize_hparams()\n",
    "saatchi_data = SaatchiDataModule(target_selection='price',\n",
    "                                  batch_size=hparams['batch_size'],\n",
    "                                  num_workers=1)\n",
    "\n",
    "results = []\n",
    "\n",
    "hparam_list = []\n",
    "\n",
    "num_sanity_val_steps = 0\n",
    "max_epochs = 25\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tracker_list = []\n",
    "\n",
    "def train(run):\n",
    "\n",
    "  hparams = randomize_hparams()\n",
    "\n",
    "  saatchi_mlp = SaatchiMLP()\n",
    "\n",
    "  trainer = pl.Trainer(gpus=1,\n",
    "                      max_epochs=max_epochs,\n",
    "                      progress_bar_refresh_rate=0,\n",
    "                      gradient_clip_val=hparams['gradient_clip_val'],\n",
    "                      gradient_clip_algorithm=hparams['gradient_clip_algorithm'],\n",
    "                      stochastic_weight_avg=hparams['stochastic_weight_avg'],\n",
    "                       weights_summary=None\n",
    "                      )\n",
    "  print('Training...')\n",
    "  trainer.fit(saatchi_mlp, saatchi_data)\n",
    "  print(f'Run {run} best accuracy: {accuracy_tracker.get_accuracy_value * 100}%, hparams: {hparams}')\n",
    "\n",
    "for i in range(100):\n",
    "  step_counter = StepCounter()\n",
    "  accuracy_tracker = AccuracyTracker(i)\n",
    "\n",
    "  train(i)\n",
    "  hparam_list.append({i: hparams})\n",
    "\n",
    "  tracker_list.append(accuracy_tracker)\n",
    "  results.append(accuracy_tracker.get_accuracy_value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s = SaatchiDataset(stage='train', target_selection='price')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s.__getitem__(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df.to_excel('saatchi_micro_512d.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "thesis_cur-ai-tor",
   "language": "python",
   "display_name": "Thesis_cur-AI-tor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}