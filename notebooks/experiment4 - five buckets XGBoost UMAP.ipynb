{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import ujson as json\n",
    "    import umap\n",
    "except ModuleNotFoundError:\n",
    "    ! pip install ujson -qU\n",
    "    ! pip install umap-learn -qU\n",
    "    import ujson as json\n",
    "    import umap\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    on_colab = True\n",
    "else:\n",
    "    on_colab = False\n",
    "\n",
    "# xgb_mode = 'gbtree'\n",
    "xgb_mode = 'dart'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper function to download files\n",
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "    return local_filename"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper function to pick random parameter from iterable or range\n",
    "def random_element(parameter_iterable):\n",
    "    # If it's a tuple treat it as an upper and lower bound\n",
    "    if isinstance(parameter_iterable, tuple):\n",
    "        out = random.uniform(parameter_iterable[0], parameter_iterable[1])\n",
    "        return round(out, 6)\n",
    "\n",
    "    # If it's a list, return a random element from the list\n",
    "    elif isinstance(parameter_iterable, list):\n",
    "        no_choices = len(parameter_iterable)\n",
    "        return parameter_iterable[random.randrange(0, no_choices)]\n",
    "\n",
    "    else:\n",
    "        print('Input not a tuple or list.')\n",
    "        raise TypeError"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dart booster\n",
    "learning_task_parameters = {'seed': 3}\n",
    "\n",
    "dart_general_parameters = {'booster': random_element(['gbtree', 'dart']), 'nthread': 2}\n",
    "\n",
    "gbtree_general_parameters = {'booster': 'gbtree', 'nthread': 2}\n",
    "\n",
    "def randomize_hparams():\n",
    "    if xgb_mode == 'dart':\n",
    "        booster_parameters_ = {'learning_rate': random_element((0.1, 0.8)),\n",
    "                              'gamma': random_element((0, 5)),\n",
    "                              'max_depth': random_element(list(range(3,12))),\n",
    "                              'min_child_weight': random_element((0, 3)),\n",
    "                              'max_delta_step': 0,\n",
    "                              'subsample': random_element((0.4, 0.8)),\n",
    "                              'sampling_method': random_element(['uniform', 'gradient_based']),\n",
    "                              'lambda': random_element((0.3, 3)),\n",
    "                              'alpha': random_element((0, 2)),\n",
    "                              'grow_policy': random_element(['depthwise', 'lossguide']),\n",
    "                              'max_leaves': random_element([1, 2, 3, 4]),\n",
    "                              'sample_type': random_element(['uniform', 'weighted']),\n",
    "                              'normalize_type': random_element(['tree', 'forest']),\n",
    "                              'rate_drop': random_element((0, 1)),\n",
    "                              'one_drop': random_element([0, 1]),\n",
    "                              }\n",
    "\n",
    "    elif xgb_mode == 'gbtree':\n",
    "        booster_parameters_ = {'learning_rate': random_element((0.1, 0.8)),\n",
    "                              'gamma': random_element((0, 5)),\n",
    "                              'max_depth': random_element(list(range(3,12))),\n",
    "                              'min_child_weight': random_element((0, 3)),\n",
    "                              'max_delta_step': 0,\n",
    "                              'subsample': random_element((0.4, 0.8)),\n",
    "                              'sampling_method': random_element(['uniform', 'gradient_based']),\n",
    "                              'lambda': random_element((0.3, 3)),\n",
    "                              'alpha': random_element((0, 2)),\n",
    "                              'grow_policy': random_element(['depthwise', 'lossguide']),\n",
    "                              'max_leaves': random_element([1, 2, 3, 4]),\n",
    "                              }\n",
    "    else:\n",
    "        print('\"Global varialbe \"xgb_mode\" not set!')\n",
    "        raise TypeError\n",
    "\n",
    "    if on_colab:\n",
    "        booster_parameters_.update({'tree_method': 'gpu_hist'})\n",
    "    else:\n",
    "        booster_parameters_.update({'tree_method': 'auto'})\n",
    "    return booster_parameters_\n",
    "\n",
    "booster_parameters = randomize_hparams()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load x data\n",
    "if on_colab:\n",
    "    download_file('https://objectstorage.eu-frankfurt-1.oraclecloud.com/n/frwwzrj6ghal/b/thesis/o/micro_dataset1_resnet18_output_identity.json')\n",
    "    data_dir = r'micro_dataset1_resnet18_output_identity.json'\n",
    "    booster_parameters.update({'tree_method': 'gpu_hist'})\n",
    "else:\n",
    "    data_dir = r'F:\\temp\\thesisdata\\micro_dataset_1\\micro_dataset1_resnet18_output_identity.json'\n",
    "\n",
    "with open(data_dir, 'r') as f:\n",
    "    data_dict_list = json.load(f)\n",
    "\n",
    "data_dict = {}\n",
    "for element in data_dict_list:\n",
    "    data_dict.update(element)\n",
    "\n",
    "# Show first two elements of the dict\n",
    "# dict(itertools.islice(data_dict.items(), 2))\n",
    "df_x = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "df_x.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load y data\n",
    "if on_colab:\n",
    "    download_file('https://objectstorage.eu-frankfurt-1.oraclecloud.com/n/frwwzrj6ghal/b/thesis/o/SAATCHI_MICRO_DATASET_PRICE_VIEWSLIKES.tsv')\n",
    "    data_dir = 'SAATCHI_MICRO_DATASET_PRICE_VIEWSLIKES.tsv'\n",
    "else:\n",
    "    data_dir = r'F:\\temp\\thesisdata\\SAATCHI_MICRO_DATASET_PRICE_VIEWSLIKES.tsv'\n",
    "\n",
    "df_y = pd.read_csv(data_dir, sep='\\t')\n",
    "df_y.set_index('FILENAME', inplace=True)\n",
    "\n",
    "# Bin the data\n",
    "# df_y['PRICE_BIN'] = pd.qcut(df_y['PRICE'], q=5)\n",
    "df_y['PRICE_BIN_IDX'] = pd.qcut(df_y['PRICE'], q=5, labels=[0, 1, 2, 3, 4])\n",
    "# df_y['LIKES_VIEWS_RATIO_BIN'] = pd.qcut(df_y['LIKES_VIEWS_RATIO'], q=5)\n",
    "df_y['LIKES_VIEWS_RATIO_BIN_IDX'] = pd.qcut(df_y['LIKES_VIEWS_RATIO'], q=5, labels=[0, 1, 2, 3, 4])\n",
    "df_y = df_y.astype({'PRICE_BIN_IDX': int, 'LIKES_VIEWS_RATIO_BIN_IDX': int})\n",
    "df_y.drop(['PRICE', 'LIKES_VIEWS_RATIO'], axis=1, inplace=True)\n",
    "\n",
    "df_y.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Join x and y into a single dataframe\n",
    "df = df_y.join(df_x)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.drop(['PRICE_BIN_IDX', 'LIKES_VIEWS_RATIO_BIN_IDX'], axis=1).values\n",
    "y = pd.get_dummies(df['LIKES_VIEWS_RATIO_BIN_IDX'].values).to_numpy()\n",
    "y_idx = df['LIKES_VIEWS_RATIO_BIN_IDX'].values\n",
    "\n",
    "X_train, X_val, X_test = X[:13000], X[12000:13000], X[13000:]\n",
    "y_train, y_val, y_test = y[:13000], y[12000:13000], y[13000:]\n",
    "y_idx_train, y_idx_val, y_idx_test = y_idx[:13000], y_idx[12000:13000], y_idx[13000:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reduce dimensionality\n",
    "reducer = umap.UMAP(n_neighbors=30, min_dist=0.0, n_components=50)\n",
    "\n",
    "mapper = umap.UMAP(n_neighbors=30, min_dist=0.0, n_components=50).fit(X_train, y=y_idx_train)\n",
    "\n",
    "X_train_embedding = mapper.transform(X_train)\n",
    "X_test_embedding = mapper.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training\n",
    "no_iterations = 100\n",
    "for i in range(no_iterations):\n",
    "    # create XGBoost instance with default hyper-parameters\n",
    "    xgb_estimator = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                                      use_label_encoder=False)\n",
    "\n",
    "    booster_parameters = randomize_hparams()\n",
    "    xgb_estimator.set_params(**booster_parameters)\n",
    "\n",
    "    # create MultiOutputClassifier instance with XGBoost model inside\n",
    "    multilabel_model = MultiOutputClassifier(xgb_estimator, n_jobs=1)\n",
    "\n",
    "    multilabel_model.fit(X_train_embedding, y_train)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, multilabel_model.predict(X_test_embedding)) * 100\n",
    "    # print(f'Accuracy on test data: {accuracy}')\n",
    "\n",
    "    r_ = {'run': i,\n",
    "                    'accuracy': accuracy,\n",
    "                    'hparams': booster_parameters}\n",
    "\n",
    "    print(r_)\n",
    "    results.append(r_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}